{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "295b9adb",
      "metadata": {
        "id": "295b9adb"
      },
      "source": [
        "# 1-Librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "717e54e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "717e54e3",
        "outputId": "97b620bb-a1f2-4916-9d20-384f01030242"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "import kagglehub\n",
        "\n",
        "# Standard libraries\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm as notebook_tqdm\n",
        "\n",
        "# tensorflow libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# keras libraries\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# scikit-learn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Suppression des warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d0fec21",
      "metadata": {
        "id": "6d0fec21"
      },
      "source": [
        "# 2-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7806030",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7806030",
        "outputId": "2dfb7fae-6a57-4d86-e467-e1aad2c89fc2"
      },
      "outputs": [],
      "source": [
        "# Téléchargement du dataset depuis Kaggle\n",
        "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "print(\"Chemin d'accés du dossier du Dataset:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a3c2c4",
      "metadata": {
        "id": "d2a3c2c4"
      },
      "outputs": [],
      "source": [
        "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc4f048",
      "metadata": {
        "id": "4bc4f048"
      },
      "source": [
        "## 2.1-Dataset Entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb73fa0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abb73fa0",
        "outputId": "e8d49225-087c-46e9-a75b-813eb81f66dc"
      },
      "outputs": [],
      "source": [
        "# Création de train_df à partir du dossier Training\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "# Utiliser explicitement la liste des noms de classes pour éviter le conflit avec la variable labels (one-hot)\n",
        "for category in class_names:\n",
        "    category_path = os.path.join(path, \"Training\", category)\n",
        "    for img_name in os.listdir(category_path):\n",
        "        train_images.append(os.path.join(category_path, img_name))\n",
        "        train_labels.append(category)\n",
        "\n",
        "# Création du DataFrame train_df\n",
        "train_df = pd.DataFrame({\"image_path\": train_images, \"label\": train_labels})\n",
        "\n",
        "X_train = train_df[\"image_path\"].values\n",
        "y_train = train_df[\"label\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27c7cc2a",
      "metadata": {
        "id": "27c7cc2a"
      },
      "source": [
        "## 2.2-Dataset Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b895aec4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b895aec4",
        "outputId": "5b2bd4a4-2ae9-4596-dc60-f2dad3257760"
      },
      "outputs": [],
      "source": [
        "# Création de test_df à partir du dossier Testing\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for category in class_names:\n",
        "    category_path = os.path.join(path, \"Testing\", category)\n",
        "    for img_name in os.listdir(category_path):\n",
        "        test_images.append(os.path.join(category_path, img_name))\n",
        "        test_labels.append(category)\n",
        "\n",
        "test_df = pd.DataFrame({\"image_path\": test_images, \"label\": test_labels})\n",
        "\n",
        "X_test = test_df[\"image_path\"].values\n",
        "y_test = test_df[\"label\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6018b5fd",
      "metadata": {
        "id": "6018b5fd"
      },
      "source": [
        "## 2.3-Dataset de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff29c104",
      "metadata": {
        "id": "ff29c104"
      },
      "outputs": [],
      "source": [
        "# Creation d'un dataset de validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_df[\"image_path\"].to_numpy(),\n",
        "    train_df[\"label\"].to_numpy(),\n",
        "    train_size=0.7,\n",
        "    random_state=42,\n",
        "    stratify=train_df[\"label\"],\n",
        ")\n",
        "val_df = pd.DataFrame({'image_path': X_val, 'label': y_val})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29cd1165",
      "metadata": {
        "id": "29cd1165"
      },
      "source": [
        "# 3-Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de75704",
      "metadata": {},
      "source": [
        "## 3.1-Normaliser le dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd85b13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "8dd85b13",
        "outputId": "65db63d4-4382-4667-ae41-bc66b08a81bc"
      },
      "outputs": [],
      "source": [
        "# Taille du batch\n",
        "batch_size = 32\n",
        "\n",
        "# Taille des images\n",
        "# Note: Les images sont redimensionnées à 224x224 pixels pour correspondre à l'entrée du modèle\n",
        "img_size = (224,224)  # Taille des images (hauteur, largeur)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "# Mode de couleur des images\n",
        "color_mode = 'rgb'  # Couleur des images (RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655baf2d",
      "metadata": {},
      "source": [
        "## 3.2-Création des générateurs d'images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fc1f58",
      "metadata": {},
      "outputs": [],
      "source": [
        "_gen = ImageDataGenerator(\n",
        "    horizontal_flip=True,  # Retourner les images horizontalement\n",
        "    rescale=1./255,\n",
        ")\n",
        "# genérateur pour les données d'entraînement\n",
        "train_gen = _gen.flow_from_dataframe(\n",
        "    train_df, x_col='image_path', y_col='label',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode=color_mode,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "# Générateur pour les données de validation\n",
        "valid_gen = _gen.flow_from_dataframe(\n",
        "    val_df, x_col='image_path', y_col='label',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode=color_mode,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "# Générateur pour les données de test\n",
        "test_gen = _gen.flow_from_dataframe(\n",
        "    test_df, x_col='image_path', y_col='label',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode=color_mode,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "336fcc6b",
      "metadata": {},
      "source": [
        "## 3.3-Visualisation du preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238d65e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_batch(dataset, title=\"Batch d'images\", num_images=9, figsize=(12, 12)):\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(min(num_images, len(images))):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            \n",
        "            # Récupérer et préparer l'image pour l'affichage\n",
        "            image = images[i].numpy()\n",
        "            \n",
        "            # Si l'image est normalisée [-1, 1], la ramener à [0, 1]\n",
        "            if image.min() < 0:\n",
        "                image = (image + 1) / 2\n",
        "            \n",
        "            # Si les valeurs sont > 1, normaliser\n",
        "            if image.max() > 1:\n",
        "                image = image / 255.0\n",
        "            \n",
        "            plt.imshow(image)\n",
        "            plt.title(f\"{class_names[labels[i]]}\", fontsize=12, pad=10)\n",
        "            plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Fonction de visualisation créée\")\n",
        "\n",
        "# Affichage d'un batch d'images originales du générateur d'entraînement\n",
        "print(\"Aperçu des images originales du dataset:\")\n",
        "print(\"Note: Images redimensionnées à 224x224 pour permettre l'affichage en batch\")\n",
        "batch_images, batch_labels = next(train_gen)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.suptitle(\"Images Originales (redimensionnées pour affichage)\", fontsize=16, fontweight='bold')\n",
        "for i in range(10):\n",
        "    ax = plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(batch_images[i])\n",
        "    plt.title(f\"{class_names[np.argmax(batch_labels[i])]}\", fontsize=12, pad=10)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Affichage après préprocessing (sans augmentation)\n",
        "# La fonction preprocess_image n'est pas définie car ImageDataGenerator gère déjà le préprocessing.\n",
        "# Si vous souhaitez visualiser les images prétraitées, utilisez simplement le générateur train_gen.\n",
        "# Exemple : afficher un batch du générateur d'entraînement (déjà prétraité)\n",
        "batch_images, batch_labels = next(train_gen)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.suptitle(\"Images Après Préprocessing (224x224, normalisées)\", fontsize=16, fontweight='bold')\n",
        "for i in range(10):\n",
        "    ax = plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(batch_images[i])\n",
        "    plt.title(f\"{class_names[np.argmax(batch_labels[i])]}\", fontsize=12, pad=10)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "effcf5a7",
      "metadata": {
        "id": "effcf5a7"
      },
      "source": [
        "# 4-CNN (Réseau Convolutif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb1e4d6",
      "metadata": {
        "id": "3cb1e4d6"
      },
      "source": [
        "## 4.1-Création du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e09614c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "3e09614c",
        "outputId": "683cb5a8-622c-45ad-cd65-92a71a7a01e2"
      },
      "outputs": [],
      "source": [
        "# Création du modèle CNN\n",
        "def create_cnn_model(img_shape, num_classes=4):\n",
        "\n",
        "    model=Sequential([\n",
        "\n",
        "        # Premier bloc convolutionnel\n",
        "        Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Deuxième bloc convolutionnel\n",
        "        Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Troisième bloc convolutionnel\n",
        "        Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Classification\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(512,activation = \"relu\"),\n",
        "        Dense(num_classes, activation = \"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compilation CNN\n",
        "def compile_models(cnn_model):\n",
        "    compile_config= {\n",
        "        'optimizer': Adam(learning_rate=0.001, decay=1e-6),\n",
        "        'loss': 'categorical_crossentropy',\n",
        "        'metrics': ['accuracy', 'Precision', 'Recall']\n",
        "    }\n",
        "\n",
        "    # Compilation du modèle\n",
        "    cnn_model.compile(**compile_config)\n",
        "\n",
        "    return cnn_model\n",
        "\n",
        "# Création du modèle CNN avec les bonnes dimensions et nombre de classes\n",
        "cnn_model = create_cnn_model(img_shape, num_classes=4)\n",
        "\n",
        "# Compiler le modele CNN\n",
        "cnn_model = compile_models(cnn_model)\n",
        "\n",
        "# Affichage des architectures\n",
        "print(\"\\n=== ARCHITECTURE CNN ===\")\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fda4b43",
      "metadata": {
        "id": "9fda4b43"
      },
      "source": [
        "## 4.2-Entrainement du modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e98f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2e98f1b",
        "outputId": "08e1b9b6-f0e5-4e74-cd4d-8f2314a3478b"
      },
      "outputs": [],
      "source": [
        "# Création des callbacks\n",
        "def create_callbacks():\n",
        "    callbacks_list = [\n",
        "\n",
        "        # Sauvegarde du meilleur modèle\n",
        "        callbacks.ModelCheckpoint(\n",
        "            './models/model_cnn_US2_v1.keras',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "\n",
        "        # Early stopping pour éviter l'overfitting\n",
        "        callbacks.EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=1,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1,\n",
        "        ),\n",
        "\n",
        "        # TensorBoard pour le monitoring\n",
        "        callbacks.TensorBoard(\n",
        "            './logs',\n",
        "            histogram_freq=1,\n",
        "            write_graph=True,\n",
        "            write_images=True\n",
        "        )\n",
        "    ]\n",
        "    return callbacks_list\n",
        "\n",
        "# Création des callbacks\n",
        "callbacks_list = create_callbacks()\n",
        "\n",
        "# Entraînement du modèle\n",
        "print(\"=== Début de l'entraînement ===\")\n",
        "\n",
        "history = cnn_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"=== Entraînement terminé ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RG__h8vfn_mI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG__h8vfn_mI",
        "outputId": "19f6aa70-12e5-4104-cd1e-e927278d44f2"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58c42165",
      "metadata": {
        "id": "58c42165"
      },
      "source": [
        "## 4.3-Evaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7yditWA_ni7u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yditWA_ni7u",
        "outputId": "79cdbcf2-4652-41cb-dfa2-fdbe5d09fa7a"
      },
      "outputs": [],
      "source": [
        "# Evaluation du modèle\n",
        "loss, accuracy, precision, recall= cnn_model.evaluate(test_gen)\n",
        "print(f\"Test Loss: {loss:0.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:0.4f}\")\n",
        "print(f\"Test Precision: {precision:0.4f}\")\n",
        "print(f\"Test Recall: {recall:0.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deeb26d8",
      "metadata": {
        "id": "deeb26d8"
      },
      "source": [
        "## 4.4-Visualisation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mYTNK1S-EHRF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "mYTNK1S-EHRF",
        "outputId": "056b1553-c098-4837-c4f4-5be62e38991b"
      },
      "outputs": [],
      "source": [
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "tr_per = history.history['precision']\n",
        "tr_recall = history.history['recall']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "val_per = history.history['val_precision']\n",
        "val_recall = history.history['val_recall']\n",
        "\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "index_precision = np.argmax(val_per)\n",
        "per_highest = val_per[index_precision]\n",
        "index_recall = np.argmax(val_recall)\n",
        "recall_highest = val_recall[index_recall]\n",
        "\n",
        "Epochs = [i + 1 for i in range(len(tr_acc))]\n",
        "loss_label = f'Best epoch = {str(index_loss + 1)}'\n",
        "acc_label = f'Best epoch = {str(index_acc + 1)}'\n",
        "per_label = f'Best epoch = {str(index_precision + 1)}'\n",
        "recall_label = f'Best epoch = {str(index_recall + 1)}'\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 12))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# affichage des métriques Loss d'entraînement et de validation\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label='Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label='Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s=150, c='blue', label=loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Affichage des métriques Accuracy d'entraînement et de validation\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label='Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label='Validation Accuracy')\n",
        "plt.scatter(index_acc + 1, acc_highest, s=150, c='blue', label=acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Affichage des métriques de précision\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(Epochs, tr_per, 'r', label='Precision')\n",
        "plt.plot(Epochs, val_per, 'g', label='Validation Precision')\n",
        "plt.scatter(index_precision + 1, per_highest, s=150, c='blue', label=per_label)\n",
        "plt.title('Precision and Validation Precision')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Affichage des métriques de rappel\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(Epochs, tr_recall, 'r', label='Recall')\n",
        "plt.plot(Epochs, val_recall, 'g', label='Validation Recall')\n",
        "plt.scatter(index_recall + 1, recall_highest, s=150, c='blue', label=recall_label)\n",
        "plt.title('Recall and Validation Recall')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.suptitle('Métriques d_entrainement sur le modèle', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WvfeemjSEmZZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvfeemjSEmZZ",
        "outputId": "d2f6a31d-e084-48e6-b467-1b3e25373629"
      },
      "outputs": [],
      "source": [
        "# Matrice de Confusion et rapport de classification\n",
        "\n",
        "def test_model(model, test_gen):\n",
        "    # Charger les poids du meilleur modèle sauvegardé\n",
        "    model.load_weights('./models/model_cnn_US2_v1.keras')\n",
        "    predictions = model.predict(test_gen)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = test_gen.classes\n",
        "    test_acc = 100 * np.sum(predicted_classes == true_classes) / len(true_classes)\n",
        "    \n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "    \n",
        "    print(\"Classification Report:\\n\")\n",
        "    print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
        "\n",
        "    cm = confusion_matrix(true_classes, predicted_classes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nLoading best model for testing...\")\n",
        "try:\n",
        "    cnn_model\n",
        "except NameError:\n",
        "    print(\"Erreur : 'cnn_model' n'est pas défini. Veuillez vérifier l'entraînement du modèle.\")\n",
        "else:\n",
        "    test_model(cnn_model, test_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0964e9f9",
      "metadata": {
        "id": "0964e9f9"
      },
      "source": [
        "# 5-Prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4twyYHpjFU1i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4twyYHpjFU1i",
        "outputId": "acbf3777-effa-47c7-8f48-764212a5b0e6"
      },
      "outputs": [],
      "source": [
        "# Visualisation des prédictions\n",
        "def visualize_predictions(model, generator, num_samples=8):\n",
        "    \n",
        "    # Charger les poids du modèle\n",
        "    model.load_weights('model_cnn_US2.v1.keras')\n",
        "    \n",
        "    # Obtenir un batch d'images et leurs étiquettes\n",
        "    x, y_true = next(generator)\n",
        "    y_pred = model.predict(x)\n",
        "    \n",
        "    # Convertir les étiquettes vraies et prédites en classes \n",
        "    true_classes = np.argmax(y_true, axis=1)\n",
        "    pred_classes = np.argmax(y_pred, axis=1)\n",
        "    \n",
        "    # Trouver les indices des classes correctes et incorrectes\n",
        "    correct_indices = np.where(true_classes == pred_classes)[0]\n",
        "    incorrect_indices = np.where(true_classes != pred_classes)[0]\n",
        "    \n",
        "    # Selectioner un nombre équilibré d'images correctes et incorrectes\n",
        "    num_correct = min(num_samples//2, len(correct_indices))\n",
        "    num_incorrect = min(num_samples//2, len(incorrect_indices))\n",
        "    \n",
        "    selected_correct = np.random.choice(correct_indices, num_correct, replace=False)\n",
        "    selected_incorrect = np.random.choice(incorrect_indices, num_incorrect, replace=False)\n",
        "    selected_indices = np.concatenate([selected_correct, selected_incorrect])\n",
        "    \n",
        "    # Visualisation\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    gs = gridspec.GridSpec(2, num_samples//2, height_ratios=[4, 4])\n",
        "    \n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        \n",
        "        plt.subplot(gs[i])\n",
        "        img = x[idx]\n",
        "        if img.shape[-1] == 1:  # si l'image est en niveaux de gris\n",
        "            img = np.concatenate([img]*3, axis=-1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        \n",
        "        # Determine si la prédiction est correcte\n",
        "        is_correct = true_classes[idx] == pred_classes[idx]\n",
        "        \n",
        "        # Ajouter les étiquettes de classe\n",
        "        true_label = class_names[int(true_classes[idx])]\n",
        "        pred_label = class_names[int(pred_classes[idx])]\n",
        "        \n",
        "        title_color = 'green' if is_correct else 'red'\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", \n",
        "                color=title_color, fontsize=10)\n",
        "        \n",
        "        # Ajouter la confiance de la prédiction\n",
        "        confidence = np.max(y_pred[idx]) * 100\n",
        "        plt.text(5, 15, f\"{confidence:.1f}%\", \n",
        "                bbox=dict(facecolor='white', alpha=0.8), \n",
        "                fontsize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Appeler la fonction pour visualiser les prédictions\n",
        "print(\"Visualizing predictions...\")\n",
        "visualize_predictions(cnn_model, test_gen, num_samples=8)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
